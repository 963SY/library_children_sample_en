{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/963SY/library_children_sample_en/blob/main/27_08_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50c81df",
      "metadata": {
        "id": "d50c81df"
      },
      "source": [
        "\n",
        "# Hausarbeit – Lineare Regression zur Vorhersage von **borrowed_books**\n",
        "\n",
        "Dieses Notebook ist **prüfungsfertig** und umfasst:\n",
        "- **Datenvorverarbeitung** (Missing Values, Ausreißer/Winsorize, One‑Hot‑Encoding)\n",
        "- **Partitionierung** (Train/Test) & **Skalierung**\n",
        "- **Lineares Regressionsmodell**\n",
        "- **Annahmenprüfung** (Residuen, QQ-Plot, VIF)\n",
        "- **Evaluation** (R² & RMSE, In- & Out-of-Sample)\n",
        "- **Visualisierungen** mit Matplotlib (einfaches, neutrales Styling)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ifJgub1rSFZv",
      "metadata": {
        "id": "ifJgub1rSFZv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "e7c69e04",
      "metadata": {
        "id": "e7c69e04"
      },
      "source": [
        "\n",
        "> **Hinweis (Pakete):**\n",
        "```bash\n",
        "conda install pandas matplotlib scikit-learn statsmodels\n",
        "# oder\n",
        "pip install pandas matplotlib scikit-learn statsmodels\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1c58310a",
      "metadata": {
        "id": "1c58310a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression # Corrected import\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "import warnings, re\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fac0d241",
      "metadata": {
        "id": "fac0d241"
      },
      "source": [
        "\n",
        "## 1) Daten laden & Spaltennamen bereinigen\n",
        "- Lädt `library_children.csv` (legen Sie die Datei ins gleiche Verzeichnis).\n",
        "- Spaltennamen werden **getrimmt**, in **Kleinschreibung** konvertiert und **Leerzeichen → Unterstrich**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e0f1711a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "e0f1711a",
        "outputId": "225ad978-c211-4450-f7b8-27a40f26a24a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'library_children.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2169659030.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#uploading path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"library_children.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Spalten bereinigen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'library_children.csv'"
          ]
        }
      ],
      "source": [
        "#uploading path\n",
        "path = \"library_children.csv\"\n",
        "df = pd.read_csv(path, sep=';')\n",
        "\n",
        "# Spalten bereinigen\n",
        "clean_cols = [re.sub(r\"\\s+\", \"_\", str(c)).strip(\"_\").lower() for c in df.columns]\n",
        "df.columns = clean_cols\n",
        "\n",
        "print(\"Spalten nach Bereinigung:\", list(df.columns))\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zielspalte automatisch finden (enthält 'borrow')\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    if 'borrow' in c:\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    raise KeyError(\"Keine Zielspalte gefunden (es wird eine Spalte benötigt, deren Name 'borrow' enthält).\")\n",
        "\n",
        "# Spalten, die typischerweise nicht als Features verwendet werden\n",
        "drop_if_exists = ['child_id', 'book_return_status']\n",
        "\n",
        "# Sauber löschen, falls vorhanden\n",
        "for c in drop_if_exists:\n",
        "    if c in df.columns:\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "\n",
        "print(\"Zielspalte (Target):\", target_col)"
      ],
      "metadata": {
        "id": "HXumYYCy8iKh"
      },
      "id": "HXumYYCy8iKh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "num_cols_wo_traget= [c for c in num_cols if c != target_col]\n",
        "cat_cols = [c for c in df.columns if c not in num_cols]\n",
        "for c in num_cols_wo_traget:\n",
        "    if df[c].isna().any():\n",
        "        df[c].fillna(df[c].median(), inplace=True)\n",
        "\n",
        "\n",
        "for c in cat_cols:\n",
        "    if df[c].isna().any():\n",
        "        df[c].fillna(df [c].mode(), inplace=True)\n",
        "\n",
        "df=df.dropna(subset=[target_col])\n",
        "print(\"Zeilen nach Missing-Handling:\", df.shape[0])\n"
      ],
      "metadata": {
        "id": "PnV4UZokG9KG"
      },
      "id": "PnV4UZokG9KG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check for duplicate rows\n",
        "print(\"Number of duplicate rows before removal:\", df.duplicated().sum())\n",
        "\n",
        "#Display some duplicate rows (if any)\n",
        "print(\"Sample duplicate rows:\")\n",
        "display(df[df.duplicated()].head())\n",
        "\n",
        "#Remove duplicate rows (keep the first occurrence)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "#Verify removal of duplicates\n",
        "print(\"Number of rows after removing duplicates:\", df.shape[0])\n",
        "print(\"Number of duplicate rows now:\", df.duplicated().sum())"
      ],
      "metadata": {
        "id": "15OLA5WuIEx5"
      },
      "id": "15OLA5WuIEx5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "E8mqC-SKSaMO",
      "metadata": {
        "id": "E8mqC-SKSaMO"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kvK9xeyAY_NQ",
      "metadata": {
        "id": "kvK9xeyAY_NQ"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p_6296mMZdK3",
      "metadata": {
        "id": "p_6296mMZdK3"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DlEp8V35cHvm",
      "metadata": {
        "id": "DlEp8V35cHvm"
      },
      "outputs": [],
      "source": [
        "# Convert 'fine_amount' to numeric, handling commas\n",
        "df['fine_amount'] = df['fine_amount'].astype(str).str.replace(',', '.', regex=False)\n",
        "df['fine_amount'] = pd.to_numeric(df['fine_amount'], errors='coerce')\n",
        "\n",
        "# Apply one-hot encoding to 'gender' column\n",
        "if 'gender' in df.columns:\n",
        "    df_encoded = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
        "else:\n",
        "    df_encoded = df.copy()\n",
        "\n",
        "# Calculate and display correlation\n",
        "display(df_encoded.corr(numeric_only=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PyXAhXo4c0Cy",
      "metadata": {
        "id": "PyXAhXo4c0Cy"
      },
      "outputs": [],
      "source": [
        "# Convert 'fine_amount' to numeric, handling commas\n",
        "df['fine_amount'] = df['fine_amount'].astype(str).str.replace(',', '.', regex=False)\n",
        "df['fine_amount'] = pd.to_numeric(df['fine_amount'], errors='coerce')\n",
        "\n",
        "# Apply one-hot encoding to 'gender' column\n",
        "if 'gender' in df.columns:\n",
        "    df_encoded = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
        "else:\n",
        "    df_encoded = df.copy()\n",
        "\n",
        "# Generate the heatmap using the encoded DataFrame\n",
        "sns.heatmap(df_encoded.corr(), annot=True, cmap=\"plasma\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outliers= ['borrowed_books']\n",
        "plt.rcParams ['figure.figsize']\n",
        "sns.boxplot(x=df['borrowed_books'], color=\"skyblue\") # Use the 'borrowed_books' column directly\n",
        "plt.title(\"Boxplot of Target(borrowed_books)\")\n",
        "plt.xlabel(\"borrowed_books\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hTKmQubskEae"
      },
      "id": "hTKmQubskEae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers= ['monthly_visits']\n",
        "plt.rcParams ['figure.figsize'] = [8,6]\n",
        "sns.boxplot(x=df['monthly_visits'], color=\"skyblue\") # Changed to string\n",
        "plt.title(\"Boxplot of monthly_visits\") # Updated title\n",
        "plt.xlabel(\"monthly_visits\") # Updated x-label\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9ikfEPNt1kSd"
      },
      "id": "9ikfEPNt1kSd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outliers= ['fine_amount']\n",
        "plt.rcParams ['figure.figsize'] = [8,6]\n",
        "sns.boxplot(x=df['fine_amount'], color=\"red\")\n",
        "plt.title(\"Boxplot of fine_amount\")\n",
        "plt.xlabel(\"fine_amount\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UAbck9H7_r3s"
      },
      "id": "UAbck9H7_r3s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = np.percentile (df['borrowed_books'], 25)\n",
        "Q3 = np.percentile (df['borrowed_books'], 75) # Added comma\n",
        "IQR = Q3 - Q1\n",
        "Lower_Bound = Q1 - 1.5 * IQR\n",
        "Upper_Bound = Q3 + 1.5 * IQR\n",
        "print(\"Lower_Bound\", Lower_Bound)\n",
        "print(\"Upper_Bound\", Upper_Bound)"
      ],
      "metadata": {
        "id": "yDFbBnLf3Hc4"
      },
      "id": "yDFbBnLf3Hc4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers = df[(df['borrowed_books'] >= Lower_Bound) & (df['borrowed_books'] <= Upper_Bound)]\n",
        "df_no_outliers"
      ],
      "metadata": {
        "id": "jEhEvG414668"
      },
      "id": "jEhEvG414668",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" Zeilen vor Ausreißern:\", df.shape[0])\n",
        "print (\" Zeilen nach Ausreißern:\", df_no_outliers.shape[0])"
      ],
      "metadata": {
        "id": "f-vpi-rV5tN4"
      },
      "id": "f-vpi-rV5tN4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df_no_outliers['borrowed_books'])\n",
        "plt.title(\"Boxplot nach Ausreißern\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "idJUVaWu68P9"
      },
      "id": "idJUVaWu68P9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = np.percentile (df['fine_amount'], 25)\n",
        "Q3 = np.percentile (df['fine_amount'], 75)\n",
        "IQR = Q3 - Q1\n",
        "Lower_Bound = Q1 - 1.5 * IQR\n",
        "Upper_Bound = Q3 + 1.5 * IQR\n",
        "print(\"Lower_Bound\", Lower_Bound)\n",
        "print(\"Upper_Bound\", Upper_Bound)"
      ],
      "metadata": {
        "id": "xN9QNKDPAxXm"
      },
      "id": "xN9QNKDPAxXm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_no_outliers = df[(df['fine_amount'] >= Lower_Bound) & (df['fine_amount'] <= Upper_Bound)]"
      ],
      "metadata": {
        "id": "0Ko_ch_bB0Co"
      },
      "id": "0Ko_ch_bB0Co",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"zeilen vor Ausreißern:\", df.shape[0])\n",
        "print (\" Zeilen nach Ausreißern:\", df_no_outliers.shape[0])"
      ],
      "metadata": {
        "id": "9xm1CEh6CIMq"
      },
      "id": "9xm1CEh6CIMq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df_no_outliers['fine_amount'])\n",
        "plt.title(\"Boxplot nach Ausreißern\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vr538NKiCt9D"
      },
      "id": "Vr538NKiCt9D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TmfsI1zm_V83"
      },
      "id": "TmfsI1zm_V83",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0eb318fc",
      "metadata": {
        "id": "0eb318fc"
      },
      "source": [
        "\n",
        "## 5) Dummifizierung (One‑Hot‑Encoding) für `gender`\n",
        "- Verhindert perfekte Multikollinearität durch `drop_first=True`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7759b8fb",
      "metadata": {
        "id": "7759b8fb"
      },
      "outputs": [],
      "source": [
        "\n",
        "if 'gender' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
        "display(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24205dd",
      "metadata": {
        "id": "e24205dd"
      },
      "source": [
        "\n",
        "## 6) Feature‑Matrix & Zielvariable, Train/Test‑Split, Skalierung\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0c1dd8e",
      "metadata": {
        "id": "c0c1dd8e"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[target_col])\n",
        "y = df[target_col]\n",
        "\n",
        "# Convert 'fine_amount' to numeric here before splitting and scaling\n",
        "if 'fine_amount' in X.columns:\n",
        "    X['fine_amount'] = X['fine_amount'].astype(str).str.replace(',', '.', regex=False)\n",
        "    X['fine_amount'] = pd.to_numeric(X['fine_amount'], errors='coerce')\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "num_cols_X = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "# Only scale numeric columns if there are any\n",
        "if num_cols_X:\n",
        "    X_train_scaled[num_cols_X] = scaler.fit_transform(X_train[num_cols_X])\n",
        "    X_test_scaled[num_cols_X] = scaler.transform(X_test[num_cols_X])\n",
        "\n",
        "\n",
        "print(\"Train/Test Größen:\", X_train.shape, X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00b2d949",
      "metadata": {
        "id": "00b2d949"
      },
      "source": [
        "\n",
        "## 7) Lineares Regressionsmodell & Gütemaße\n",
        "- In‑Sample (Train) & Out‑of‑Sample (Test): **R²** und **RMSE**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "712de0b0",
      "metadata": {
        "id": "712de0b0"
      },
      "outputs": [],
      "source": [
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_train_pred = lr.predict(X_train_scaled)\n",
        "y_test_pred  = lr.predict(X_test_scaled)\n",
        "\n",
        "r2_train  = r2_score(y_train, y_train_pred)\n",
        "r2_test   = r2_score(y_test, y_test_pred)\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "rmse_test  = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "\n",
        "print(f\"Train R²: {r2_train:.3f} | Test R²: {r2_test:.3f}\")\n",
        "print(f\"Train RMSE: {rmse_train:.3f} | Test RMSE: {rmse_test:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e5ff70",
      "metadata": {
        "id": "32e5ff70"
      },
      "source": [
        "\n",
        "## 8) Annahmen prüfen\n",
        "- **Residuenplot** (Homogenität, Musterfreiheit)  \n",
        "- **QQ‑Plot** der Residuen (Normalitätsannahme)  \n",
        "- **VIF** (Multikollinearität)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c29f4bc7",
      "metadata": {
        "id": "c29f4bc7"
      },
      "outputs": [],
      "source": [
        "# Residuen (Test)\n",
        "residuals = y_test - y_test_pred\n",
        "\n",
        "# Residuen vs. Vorhersage\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(y_test_pred, residuals, alpha=0.7)\n",
        "plt.axhline(0, linestyle='--')\n",
        "plt.xlabel(\"Vorhergesagte Werte\")\n",
        "plt.ylabel(\"Residuen\")\n",
        "plt.title(\"Residuenplot (Testdaten)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# QQ-Plot\n",
        "fig = sm.qqplot(residuals, line='s')\n",
        "plt.title(\"QQ-Plot der Residuen (Test)\")\n",
        "plt.show()\n",
        "\n",
        "# VIF (auf Trainingsdaten, mit Konstante)\n",
        "X_vif = X_train_scaled.copy()\n",
        "# Convert boolean columns to numeric (int) before calculating VIF\n",
        "for col in X_vif.columns:\n",
        "    if X_vif[col].dtype == 'bool':\n",
        "        X_vif[col] = X_vif[col].astype(int)\n",
        "\n",
        "X_vif_const = sm.add_constant(X_vif.values)\n",
        "vif_vals = [variance_inflation_factor(X_vif_const, i+1) for i in range(len(X_vif.columns))]\n",
        "vif_df = pd.DataFrame({\"Feature\": X_vif.columns, \"VIF\": vif_vals}).sort_values(\"VIF\", ascending=False)\n",
        "display(vif_df.head(15))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02ff0400",
      "metadata": {
        "id": "02ff0400"
      },
      "source": [
        "\n",
        "## 9) Evaluation – Visualisierungen\n",
        "- **Tatsächlich vs. Vorhergesagt** (Test)  \n",
        "- **Fehlerverteilung (Histogramm)**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d697b7b0",
      "metadata": {
        "id": "d697b7b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Tatsächlich vs. Vorhergesagt\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.scatter(y_test, y_test_pred, alpha=0.7)\n",
        "min_v, max_v = min(y_test.min(), y_test_pred.min()), max(y_test.max(), y_test_pred.max())\n",
        "plt.plot([min_v, max_v], [min_v, max_v], linestyle='--')\n",
        "plt.xlabel(\"Tatsächliche Werte\")\n",
        "plt.ylabel(\"Vorhergesagte Werte\")\n",
        "plt.title(\"Tatsächlich vs. Vorhergesagt (Test)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Histogramm der Residuen\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.hist(residuals, bins=20)\n",
        "plt.title(\"Verteilung der Residuen (Test)\")\n",
        "plt.xlabel(\"Residuum\")\n",
        "plt.ylabel(\"Häufigkeit\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O1TL3KNgIwn3",
      "metadata": {
        "id": "O1TL3KNgIwn3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "341e01bd",
      "metadata": {
        "id": "341e01bd"
      },
      "source": [
        "\n",
        "## 10) Fazit\n",
        "Das Notebook erfüllt die geforderten Bausteine der Hausarbeit:\n",
        "**Vorverarbeitung**, **Modellierung**, **Annahmenprüfung** und **Evaluation**.  \n",
        "Die Metriken (R², RMSE) geben Auskunft über die Güte der **In‑Sample** und **Out‑of‑Sample**‑Vorhersagen.  \n",
        "Je nach Datenlage sind Erweiterungen sinnvoll (z. B. Regularisierung, Feature‑Engineering oder weitere erklärende Variablen).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7759b7fb",
      "metadata": {
        "id": "7759b7fb"
      },
      "outputs": [],
      "source": [
        "if 'gender' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a00623e",
      "metadata": {
        "id": "5a00623e"
      },
      "outputs": [],
      "source": [
        "#uploading path\n",
        "path = \"library_children.csv\"\n",
        "df = pd.read_csv(path, sep=';')\n",
        "\n",
        "# Spalten bereinigen\n",
        "clean_cols = [re.sub(r\"\\s+\", \"_\", str(c)).strip(\"_\").lower() for c in df.columns]\n",
        "df.columns = clean_cols\n",
        "\n",
        "print(\"Spalten nach Bereinigung:\", list(df.columns))\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "994fa646"
      },
      "source": [
        "# Zielspalte automatisch finden (enthält 'borrow')\n",
        "target_col = None\n",
        "for c in df.columns:\n",
        "    if 'borrow' in c:\n",
        "        target_col = c\n",
        "        break\n",
        "if target_col is None:\n",
        "    raise KeyError(\"Keine Zielspalte gefunden (es wird eine Spalte benötigt, deren Name 'borrow' enthält).\")\n",
        "\n",
        "# Spalten, die typischerweise nicht als Features verwendet werden\n",
        "drop_if_exists = ['child_id', 'book_return_status']\n",
        "\n",
        "# Sauber löschen, falls vorhanden\n",
        "for c in drop_if_exists:\n",
        "    if c in df.columns:\n",
        "        df.drop(columns=[c], inplace=True)\n",
        "\n",
        "print(\"Zielspalte (Target):\", target_col)"
      ],
      "id": "994fa646",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bef5abe"
      },
      "source": [
        "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_cols = [c for c in df.columns if c not in num_cols]\n",
        "\n",
        "# Zielspalte nicht anfassen, falls numerisch\n",
        "num_cols_wo_target = [c for c in num_cols if c != target_col]\n",
        "\n",
        "for c in num_cols_wo_target:\n",
        "    if df[c].isna().any():\n",
        "        df[c].fillna(df[c].median(), inplace=True)\n",
        "\n",
        "for c in cat_cols:\n",
        "    if df[c].isna().any():\n",
        "        df[c].fillna('unbekannt', inplace=True)\n",
        "\n",
        "# Ziel: falls NA, löschen (optional auch Median möglich, aber hier entfernen wir wenige Fälle)\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "print(\"Zeilen nach Missing-Handling:\", df.shape[0])"
      ],
      "id": "0bef5abe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74f4ee4c"
      },
      "source": [
        "if 'gender' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['gender'], drop_first=True)\n",
        "display(df.head())"
      ],
      "id": "74f4ee4c",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}